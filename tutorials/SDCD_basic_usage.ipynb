{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Differentiable Causal Discovery (SDCD) Tutorial\n",
    "\n",
    "In this brief tutorial, we will go over the main API for the `sdcd` package. SDCD is a differentiable causal discovery method designed to scale reliably to hundreds and thousands of variables. The algorithm is implemented in vanilla PyTorch and also uses the `networkx` package. \n",
    "\n",
    "(Note, under the default pip installation, only the packages necessary to run the `SDCD` model are installed. If you would also like to run other causal discovery methods implemented in this package, you must also install the `benchmark` extra via the `pip install sdcd[benchmark]` command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sdcd.models import SDCD\n",
    "from sdcd.utils import create_intervention_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by simulating some data for the tutorial. If you have your own data, you can ignore this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Data\n",
    "from sdcd.simulated_data import random_model_gaussian_global_variance # For demonstration\n",
    "\n",
    "n = 200\n",
    "n_per_intervention = 50\n",
    "d = 20\n",
    "n_edges = 20\n",
    "\n",
    "true_causal_model = random_model_gaussian_global_variance(\n",
    "    d,\n",
    "    n_edges,\n",
    "    dag_type=\"ER\",\n",
    "    scale=0.5,\n",
    "    hard=True,\n",
    ")\n",
    "X_df = true_causal_model.generate_dataframe_from_all_distributions(\n",
    "    n_samples_control=n,\n",
    "    n_samples_per_intervention=n_per_intervention,\n",
    ")\n",
    "X_df.iloc[:, :-1] = (X_df.iloc[:, :-1] - X_df.iloc[:, :-1].mean()) / X_df.iloc[\n",
    "    :, :-1\n",
    "].std() # Normalize the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data should be formatted as a Pandas Dataframe where each row corresponds to one observation and each column corresponds to one variable. There should be an additional column reports which variable(s) was intervened on for the given observation. Here it is labeled as `perturbation_label`. For rows that do not have any interventions, the value should be set to `\"obs\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>perturbation_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871384</td>\n",
       "      <td>-1.298243</td>\n",
       "      <td>-0.541056</td>\n",
       "      <td>-0.839735</td>\n",
       "      <td>0.385079</td>\n",
       "      <td>-0.172131</td>\n",
       "      <td>0.417135</td>\n",
       "      <td>0.439012</td>\n",
       "      <td>1.084618</td>\n",
       "      <td>-0.942723</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.293240</td>\n",
       "      <td>-0.209410</td>\n",
       "      <td>-1.180888</td>\n",
       "      <td>-0.450958</td>\n",
       "      <td>2.148383</td>\n",
       "      <td>3.076456</td>\n",
       "      <td>-1.035478</td>\n",
       "      <td>-1.569835</td>\n",
       "      <td>0.864200</td>\n",
       "      <td>obs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.219530</td>\n",
       "      <td>-1.217384</td>\n",
       "      <td>-0.719318</td>\n",
       "      <td>0.067425</td>\n",
       "      <td>0.049899</td>\n",
       "      <td>1.223961</td>\n",
       "      <td>-0.048282</td>\n",
       "      <td>-0.314315</td>\n",
       "      <td>-0.728916</td>\n",
       "      <td>-0.923227</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.319596</td>\n",
       "      <td>-0.001921</td>\n",
       "      <td>-1.191708</td>\n",
       "      <td>0.904951</td>\n",
       "      <td>1.143647</td>\n",
       "      <td>-0.797360</td>\n",
       "      <td>-1.061556</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>-0.110571</td>\n",
       "      <td>obs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.060095</td>\n",
       "      <td>-0.105745</td>\n",
       "      <td>0.132579</td>\n",
       "      <td>-0.561208</td>\n",
       "      <td>-0.673707</td>\n",
       "      <td>1.175806</td>\n",
       "      <td>1.349005</td>\n",
       "      <td>1.170219</td>\n",
       "      <td>-0.030465</td>\n",
       "      <td>-0.292935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647847</td>\n",
       "      <td>-0.284626</td>\n",
       "      <td>-0.109206</td>\n",
       "      <td>-0.166495</td>\n",
       "      <td>-0.533553</td>\n",
       "      <td>-1.087932</td>\n",
       "      <td>-0.174844</td>\n",
       "      <td>-0.665772</td>\n",
       "      <td>-0.233534</td>\n",
       "      <td>obs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386371</td>\n",
       "      <td>-0.478593</td>\n",
       "      <td>-0.286767</td>\n",
       "      <td>-0.131907</td>\n",
       "      <td>-0.096226</td>\n",
       "      <td>0.747864</td>\n",
       "      <td>-0.326589</td>\n",
       "      <td>-0.493890</td>\n",
       "      <td>0.804010</td>\n",
       "      <td>-0.317977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308801</td>\n",
       "      <td>-0.133661</td>\n",
       "      <td>-0.283226</td>\n",
       "      <td>-0.407182</td>\n",
       "      <td>0.385180</td>\n",
       "      <td>-0.711048</td>\n",
       "      <td>-0.355081</td>\n",
       "      <td>0.509291</td>\n",
       "      <td>0.335167</td>\n",
       "      <td>obs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.459966</td>\n",
       "      <td>1.277083</td>\n",
       "      <td>1.056286</td>\n",
       "      <td>-0.432633</td>\n",
       "      <td>0.393007</td>\n",
       "      <td>-1.427799</td>\n",
       "      <td>-0.608757</td>\n",
       "      <td>-0.218208</td>\n",
       "      <td>1.930627</td>\n",
       "      <td>0.540725</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256948</td>\n",
       "      <td>-0.097415</td>\n",
       "      <td>0.927841</td>\n",
       "      <td>-1.633421</td>\n",
       "      <td>1.263645</td>\n",
       "      <td>0.780632</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>-0.496829</td>\n",
       "      <td>1.064864</td>\n",
       "      <td>obs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.871384 -1.298243 -0.541056 -0.839735  0.385079 -0.172131  0.417135   \n",
       "1  1.219530 -1.217384 -0.719318  0.067425  0.049899  1.223961 -0.048282   \n",
       "2 -1.060095 -0.105745  0.132579 -0.561208 -0.673707  1.175806  1.349005   \n",
       "3  0.386371 -0.478593 -0.286767 -0.131907 -0.096226  0.747864 -0.326589   \n",
       "4 -0.459966  1.277083  1.056286 -0.432633  0.393007 -1.427799 -0.608757   \n",
       "\n",
       "          7         8         9  ...        11        12        13        14  \\\n",
       "0  0.439012  1.084618 -0.942723  ... -1.293240 -0.209410 -1.180888 -0.450958   \n",
       "1 -0.314315 -0.728916 -0.923227  ... -1.319596 -0.001921 -1.191708  0.904951   \n",
       "2  1.170219 -0.030465 -0.292935  ... -0.647847 -0.284626 -0.109206 -0.166495   \n",
       "3 -0.493890  0.804010 -0.317977  ... -0.308801 -0.133661 -0.283226 -0.407182   \n",
       "4 -0.218208  1.930627  0.540725  ...  1.256948 -0.097415  0.927841 -1.633421   \n",
       "\n",
       "         15        16        17        18        19  perturbation_label  \n",
       "0  2.148383  3.076456 -1.035478 -1.569835  0.864200                 obs  \n",
       "1  1.143647 -0.797360 -1.061556  0.214472 -0.110571                 obs  \n",
       "2 -0.533553 -1.087932 -0.174844 -0.665772 -0.233534                 obs  \n",
       "3  0.385180 -0.711048 -0.355081  0.509291  0.335167                 obs  \n",
       "4  1.263645  0.780632  0.906074 -0.496829  1.064864                 obs  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to construct a torch dataset with the appropriate tensors, we use the utility function `sdcd.utils.create_intervention_dataset`.\n",
    " \n",
    "(Note, we also have a function `sdcd.utils.create_dataset_anndata` for users working with the AnnData data format.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x28fe46bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset = create_intervention_dataset(X_df, perturbation_colname=\"perturbation_label\")\n",
    "X_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the SDCD model. Here, we will set `finetune=True` which runs the algorithm until the final adjacency matrix is estimated and binarized, then proceeds with a final stage of training the model until it converges for the fixed, discretized adjacency matrix. If you only care about the predicted graph, you may set this to `False` to shorten the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=27.59, gamma=0.00\n",
      "Epoch 100: loss=7.35, gamma=0.00\n",
      "Epoch 200: loss=4.89, gamma=0.00\n",
      "Epoch 300: loss=3.45, gamma=0.00\n",
      "Epoch 400: loss=2.71, gamma=0.00\n",
      "Epoch 500: loss=2.15, gamma=0.00\n",
      "Epoch 600: loss=1.88, gamma=0.00\n",
      "Epoch 700: loss=1.62, gamma=0.00\n",
      "Epoch 800: loss=1.48, gamma=0.00\n",
      "Epoch 900: loss=1.28, gamma=0.00\n",
      "Epoch 1000: loss=1.16, gamma=0.00\n",
      "Epoch 1100: loss=1.03, gamma=0.00\n",
      "Epoch 1200: loss=0.93, gamma=0.00\n",
      "Epoch 1300: loss=0.83, gamma=0.00\n",
      "Epoch 1400: loss=0.72, gamma=0.00\n",
      "Epoch 1500: loss=0.66, gamma=0.00\n",
      "Epoch 1600: loss=0.57, gamma=0.00\n",
      "Epoch 1700: loss=0.49, gamma=0.00\n",
      "Epoch 1800: loss=0.44, gamma=0.00\n",
      "Epoch 1900: loss=0.36, gamma=0.00\n",
      "Fraction of possible edges in mask: 0.1775\n",
      "Epoch 0: loss=28.14, gamma=0.00\n",
      "Epoch 100: loss=14.32, gamma=0.50\n",
      "Epoch 200: loss=10.18, gamma=1.00\n",
      "Epoch 300: loss=10.33, gamma=1.50\n",
      "Epoch 400: loss=10.56, gamma=2.00\n",
      "Epoch 500: loss=10.73, gamma=2.50\n",
      "Epoch 600: loss=11.13, gamma=3.00\n",
      "Epoch 700: loss=11.63, gamma=3.50\n",
      "Epoch 800: loss=12.05, gamma=4.00\n",
      "Epoch 900: loss=12.41, gamma=4.50\n",
      "Epoch 1000: loss=12.84, gamma=5.00\n",
      "Epoch 1100: loss=12.96, gamma=5.50\n",
      "Epoch 1200: loss=13.05, gamma=6.00\n",
      "Epoch 1300: loss=13.17, gamma=6.50\n",
      "Epoch 1400: loss=13.46, gamma=7.00\n",
      "Epoch 1500: loss=13.57, gamma=7.50\n",
      "Epoch 1600: loss=13.71, gamma=8.00\n",
      "Epoch 1700: loss=14.00, gamma=8.50\n",
      "Epoch 1800: loss=14.12, gamma=9.00\n",
      "Epoch 1900: loss=14.38, gamma=9.50\n",
      "Fixing adjacency matrix.\n",
      "Beginning finetune.\n",
      "Epoch 0: loss=13.92, gamma=0.00\n",
      "Epoch 100: loss=10.78, gamma=0.00\n",
      "Epoch 200: loss=10.54, gamma=0.00\n",
      "Epoch 300: loss=10.33, gamma=0.00\n",
      "Epoch 400: loss=10.13, gamma=0.00\n",
      "Epoch 500: loss=9.89, gamma=0.00\n",
      "Epoch 600: loss=9.64, gamma=0.00\n",
      "Epoch 700: loss=9.41, gamma=0.00\n",
      "Epoch 800: loss=9.32, gamma=0.00\n",
      "Epoch 900: loss=9.24, gamma=0.00\n",
      "Epoch 1000: loss=9.18, gamma=0.00\n",
      "Epoch 1100: loss=9.14, gamma=0.00\n",
      "Epoch 1200: loss=9.11, gamma=0.00\n",
      "Epoch 1300: loss=9.08, gamma=0.00\n",
      "Epoch 1400: loss=9.04, gamma=0.00\n",
      "Epoch 1500: loss=9.01, gamma=0.00\n",
      "Epoch 1600: loss=8.98, gamma=0.00\n",
      "Epoch 1700: loss=8.92, gamma=0.00\n",
      "Epoch 1800: loss=8.87, gamma=0.00\n",
      "Epoch 1900: loss=8.79, gamma=0.00\n",
      "Finished training in 81.20726299285889 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = SDCD()\n",
    "model.train(X_dataset, finetune=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can recover the predicted adjacency matrix, both before thresholding and after thresholding, and compute likelihoods respect to a given observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "adj_matrix = model.get_adjacency_matrix(threshold=True)\n",
    "print(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 1.82328773e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.19770358e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.68300413e-04 0.00000000e+00 4.15186951e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.29337847e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.77099991e+00\n",
      "  0.00000000e+00 2.14771581e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.14851931e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.13774276e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.80197715e-04 0.00000000e+00\n",
      "  0.00000000e+00 2.43971852e-04 1.91857851e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.68017762e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.63521365e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.17269150e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.28939909e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.01546136e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.75279488e-03 0.00000000e+00\n",
      "  6.29063129e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.43145482e-04 3.84569517e-04 0.00000000e+00 0.00000000e+00]\n",
      " [2.69216371e+00 0.00000000e+00 3.03275231e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.36481845e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.00449406e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.37800294e-01\n",
      "  0.00000000e+00 0.00000000e+00 4.20749515e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.04941097e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.51583250e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.19556671e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.98586863e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.14343536e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.86906600e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 7.08368607e-04 0.00000000e+00\n",
      "  0.00000000e+00 2.79645785e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.60128534e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.08854176e-04 0.00000000e+00\n",
      "  0.00000000e+00 4.68839746e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.80157507e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.70752507e-01 8.19647685e-04 3.18331361e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.62868562e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.09150970e-01 0.00000000e+00\n",
      "  2.78337449e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.32788011e-04 0.00000000e+00 0.00000000e+00]\n",
      " [2.20714641e+00 7.91815284e-04 2.08633685e+00 0.00000000e+00\n",
      "  5.68682373e-01 1.08281207e+00 4.41609882e-03 0.00000000e+00\n",
      "  0.00000000e+00 1.67666709e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.16490269e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.15979560e-04 3.97580414e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.72778988e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.60034680e-01]\n",
      " [0.00000000e+00 0.00000000e+00 4.55520637e-02 2.59674954e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.06768134e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.46907532e-01 1.15349114e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.26939344e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.70788619e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.93277526e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.52837291e-01 2.44826031e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.71123222e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.55553794e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.74724330e-03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "adj_matrix = model.get_adjacency_matrix(threshold=False)\n",
    "print(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.453802591959636"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_nll(X_dataset) # Reports average negative log-likelihood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorial. Please raise an issue on the Github repo if you come across any issues, and we hope you find this package useful to your research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalperturb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
